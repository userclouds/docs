---
title: "Why tokenize?"
slug: "why-tokenize"
excerpt: ""
hidden: false
metadata: 
  image: []
  robots: "index"
createdAt: "Thu Aug 03 2023 21:56:27 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Fri Aug 25 2023 21:10:03 GMT+0000 (Coordinated Universal Time)"
---
Tokenization is an exceptionally efficient way to improve data security & privacy posture, without sacrificing your engineering velocity. It allows you to unlock the power of your data, without replicating it throughout data centers and third party applications.

Most companies tokenize their sensitive data to achieve three goals:

1. Strengthen Data Security
2. Simplify Privacy and Compliance
3. Improve Engineering Velocity

### 1. Strengthen Data Security

Tokenization reduces the value of data sets to hackers & internal threats, by obscuring sensitive data and separating it from its ID schema. Well-tokenized datasets are unusable without credentials. It limits the number of employees with unrestrained access to sensitive data, reducing your insider threat and account takeover risks. It makes it harder for sensitive data to get replicated in data centers and employee laptops. And it lets you automatically log when, why and by whom raw data was accessed.

### 2. Simplify Privacy & Compliance

Tokenization lets you define access policies for each token, settings constraints on when, how and by whom a token can be resolved. It allows you to apply and maintain those privacy policies centrally, even giving you the ability to modify contracts on data use after the data is shared.That means you have far less code to write, test, update and version control, so far less room for error & security flaws.

Secondly, with one single copy of PII, data deletion becomes trivial. To satisfy a deletion request, all you need to do is delete the link between PII and token in the vault. The tokens can then live on in your systems, as theyâ€™re rendered meaningless without the root PII.

Finally, it simplifies compliance with data residency regulations, since in some cases, it allows you to use tokens from anywhere, without taking sensitive data outside of home country

### 3. Improve Engineering Velocity

Fundamentally, tokenization lets you improve data security and privacy compliance in your systems without rebuilding those systems. It allows you to secure the data flowing through the systems instead. This abstraction allows you to spend less time writing, testing and updating custom code across several languages and systems - allowing your team to get back to your mission.
